{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3062fec4",
   "metadata": {},
   "source": [
    "# Checkpoint Evaluation\n",
    "Load saved checkpoints and evaluate accuracy on the test set.\n",
    "(Noise testing will be added later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e474477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and config\n",
    "ROOT_DIR = \"dataset/fruit360\"\n",
    "TEST_DIR = os.path.join(ROOT_DIR, \"Test\")\n",
    "CKPT_ROOT = Path(\"artifacts/checkpoints\")\n",
    "\n",
    "SIZE = 32\n",
    "BATCH = 128\n",
    "COLOR_BINS = 16\n",
    "VARIETY = False  # False = macro, True = fine-grained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FruitFolderDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, variety=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.variety = variety\n",
    "        self.samples = []\n",
    "\n",
    "        for class_name in sorted(os.listdir(root_dir)):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                continue\n",
    "            label_str = class_name if variety else class_name.split()[0]\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith((\".jpg\", \".png\")):\n",
    "                    self.samples.append((os.path.join(class_dir, img_name), label_str))\n",
    "\n",
    "        self.labels = sorted({lbl for _, lbl in self.samples})\n",
    "        self.label_to_idx = {lbl: i for i, lbl in enumerate(self.labels)}\n",
    "        self.idx_to_label = {i: lbl for lbl, i in self.label_to_idx.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label_str = self.samples[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        img = self.transform(image) if self.transform is not None else image\n",
    "        label_idx = self.label_to_idx[label_str]\n",
    "        return img, label_idx\n",
    "\n",
    "def dataloader_to_numpy(loader):\n",
    "    x_list, y_list = [], []\n",
    "    for batch_x, batch_y in loader:\n",
    "        if isinstance(batch_x, torch.Tensor):\n",
    "            x_list.append(batch_x.detach().cpu())\n",
    "        else:\n",
    "            x_list.append(torch.tensor(batch_x))\n",
    "        if isinstance(batch_y, torch.Tensor):\n",
    "            y_list.append(batch_y.detach().cpu())\n",
    "        else:\n",
    "            y_list.append(torch.tensor(batch_y))\n",
    "    if not x_list:\n",
    "        raise ValueError(\"Empty loader: no samples found.\")\n",
    "    X = torch.cat(x_list, dim=0).numpy()\n",
    "    y = torch.cat(y_list, dim=0).numpy()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9277b",
   "metadata": {},
   "source": [
    "# Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c215959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp01(x):\n",
    "    return torch.clamp(x, 0.0, 1.0)\n",
    "\n",
    "# Config per le trasformazioni\n",
    "NOISE_CONFIG = {\n",
    "    \"grayscale\": {},\n",
    "    \"blur_mild\": {\"kernel_size\": 3, \"sigma\": 0.5},\n",
    "    \"blur_medium\": {\"kernel_size\": 5, \"sigma\": 1.0},\n",
    "    \"blur_strong\": {\"kernel_size\": 7, \"sigma\": 2.0},\n",
    "    \"noise_mild\": {\"std\": 0.03},\n",
    "    \"noise_medium\": {\"std\": 0.07},\n",
    "    \"noise_strong\": {\"std\": 0.15},\n",
    "    \"dark\": {\"factor\": 0.4},\n",
    "    \"overexposed\": {\"factor\": 1.8},\n",
    "    \"noisy_blurred\": {\"noise_std\": 0.10, \"kernel_size\": 5, \"sigma\": 1.0}\n",
    "}\n",
    "\n",
    "# Probabilit√† per il test mixed\n",
    "MIXED_PROB_MAP = {\n",
    "    \"grayscale\": 0.20,\n",
    "    \"blur_mild\": 0.25,\n",
    "    \"blur_medium\": 0.10,\n",
    "    \"noise_mild\": 0.25,\n",
    "    \"noise_medium\": 0.15,\n",
    "    \"dark\": 0.10,\n",
    "    \"overexposed\": 0.10,\n",
    "    \"noisy_blurred\": 0.05,\n",
    "}\n",
    "\n",
    "degradations_camera = {\n",
    "    # Baseline\n",
    "    \"clean\": lambda x: x,\n",
    "\n",
    "    # Grayscale (test colore)\n",
    "    \"grayscale\": lambda x: x.mean(dim=0, keepdim=True).repeat(3, 1, 1),\n",
    "\n",
    "    # Blur (defocus / motion)\n",
    "    \"blur_mild\":   T.GaussianBlur(kernel_size=NOISE_CONFIG[\"blur_mild\"][\"kernel_size\"], sigma=NOISE_CONFIG[\"blur_mild\"][\"sigma\"]),\n",
    "    \"blur_medium\": T.GaussianBlur(kernel_size=NOISE_CONFIG[\"blur_medium\"][\"kernel_size\"], sigma=NOISE_CONFIG[\"blur_medium\"][\"sigma\"]),\n",
    "    \"blur_strong\": T.GaussianBlur(kernel_size=NOISE_CONFIG[\"blur_strong\"][\"kernel_size\"], sigma=NOISE_CONFIG[\"blur_strong\"][\"sigma\"]),\n",
    "\n",
    "    # Gaussian noise (sensore)\n",
    "    \"noise_mild\":   lambda x: clamp01(x + torch.randn_like(x) * NOISE_CONFIG[\"noise_mild\"][\"std\"]),\n",
    "    \"noise_medium\": lambda x: clamp01(x + torch.randn_like(x) * NOISE_CONFIG[\"noise_medium\"][\"std\"]),\n",
    "    \"noise_strong\": lambda x: clamp01(x + torch.randn_like(x) * NOISE_CONFIG[\"noise_strong\"][\"std\"]),\n",
    "\n",
    "    # Lighting\n",
    "    \"dark\":        lambda x: clamp01(x * NOISE_CONFIG[\"dark\"][\"factor\"]),\n",
    "    \"overexposed\": lambda x: clamp01(x * NOISE_CONFIG[\"overexposed\"][\"factor\"]),\n",
    "\n",
    "    # Combined (noise + blur moderati)\n",
    "    \"noisy_blurred\": lambda x: T.GaussianBlur(\n",
    "        kernel_size=NOISE_CONFIG[\"noisy_blurred\"][\"kernel_size\"],\n",
    "        sigma=NOISE_CONFIG[\"noisy_blurred\"][\"sigma\"]\n",
    "    )(clamp01(x + torch.randn_like(x) * NOISE_CONFIG[\"noisy_blurred\"][\"noise_std\"])),\n",
    "}\n",
    "\n",
    "def apply_degradation_batch(X_np, degradation_fn):\n",
    "    X = torch.from_numpy(X_np)\n",
    "    out = torch.empty_like(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        y = degradation_fn(x) if callable(degradation_fn) else x\n",
    "        out[i] = y\n",
    "    return out.numpy()\n",
    "\n",
    "def apply_mixed_degradations(X_np, prob_map, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = torch.from_numpy(X_np)\n",
    "    out = torch.empty_like(X)\n",
    "    keys = [k for k in prob_map.keys() if k in degradations_camera and k != \"clean\"]\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        for k in keys:\n",
    "            if rng.random() < prob_map[k]:\n",
    "                x = degradations_camera[k](x)\n",
    "        out[i] = x\n",
    "    return out.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be922a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = T.Compose([\n",
    "    T.Resize((SIZE, SIZE)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "test_dataset = FruitFolderDataset(TEST_DIR, transform=val_transform, variety=VARIETY)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH, shuffle=False)\n",
    "\n",
    "X_test_np, y_test_np = dataloader_to_numpy(test_loader)\n",
    "print(\"Test:\", X_test_np.shape, y_test_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_hist_features(X, bins=16, img_shape=(3, 64, 64)):\n",
    "    n_samples = X.shape[0]\n",
    "    feats = np.zeros((n_samples, 3 * bins), dtype=np.float32)\n",
    "    bin_edges = np.linspace(0.0, 1.0, bins + 1)\n",
    "    for i in range(n_samples):\n",
    "        img = X[i].reshape(img_shape)\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        img = np.clip(img, 0.0, 1.0)\n",
    "        img_hsv = (img * 255.0).astype(np.uint8)\n",
    "        img_hsv = cv2.cvtColor(img_hsv, cv2.COLOR_RGB2HSV)\n",
    "        h, s, v = cv2.split(img_hsv)\n",
    "        hists = []\n",
    "        for channel in (h, s, v):\n",
    "            ch_norm = channel.astype(np.float32) / 255.0\n",
    "            hist, _ = np.histogram(ch_norm.ravel(), bins=bin_edges, density=True)\n",
    "            hists.append(hist)\n",
    "        feats[i] = np.concatenate(hists)\n",
    "    return feats\n",
    "\n",
    "X_test_color = color_hist_features(X_test_np, bins=COLOR_BINS, img_shape=(3, SIZE, SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5d2244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoints and evaluate\n",
    "ckpt_model_paths = sorted(CKPT_ROOT.rglob(\"model.joblib\"))\n",
    "if not ckpt_model_paths:\n",
    "    raise FileNotFoundError(f\"No checkpoints found under {CKPT_ROOT}\")\n",
    "\n",
    "def infer_model_name(run_dir: Path):\n",
    "    parts = run_dir.parts\n",
    "    return parts[-2] if len(parts) >= 2 else \"unknown\"\n",
    "\n",
    "def evaluate_checkpoints(X_np, y_np):\n",
    "    X_color = color_hist_features(X_np, bins=COLOR_BINS, img_shape=(3, SIZE, SIZE))\n",
    "    results = []\n",
    "    for model_path in ckpt_model_paths:\n",
    "        run_dir = model_path.parent\n",
    "        scaler_path = run_dir / \"scaler.joblib\"\n",
    "        model = joblib.load(model_path)\n",
    "        scaler = joblib.load(scaler_path) if scaler_path.exists() else None\n",
    "\n",
    "        X_eval = scaler.transform(X_color) if scaler is not None else X_color\n",
    "        y_pred = model.predict(X_eval)\n",
    "        acc = accuracy_score(y_np, y_pred)\n",
    "        f1 = f1_score(y_np, y_pred, average=\"macro\")\n",
    "        rec = recall_score(y_np, y_pred, average=\"macro\")\n",
    "        model_name = infer_model_name(run_dir)\n",
    "        results.append({\n",
    "            \"run_dir\": str(run_dir),\n",
    "            \"model_name\": model_name,\n",
    "            \"acc\": acc,\n",
    "            \"f1_macro\": f1,\n",
    "            \"recall_macro\": rec\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# 1) Test set completamente sporcato per ogni rumore\n",
    "noise_keys = list(degradations_camera.keys())\n",
    "noise_results = {}\n",
    "for noise_key in noise_keys:\n",
    "    X_noisy = apply_degradation_batch(X_test_np, degradations_camera[noise_key])\n",
    "    noise_results[noise_key] = evaluate_checkpoints(X_noisy, y_test_np)\n",
    "    print(f\"Done: {noise_key}\")\n",
    "\n",
    "# 2) Test set con tutte le trasformazioni applicate con percentuali\n",
    "X_mixed = apply_mixed_degradations(X_test_np, MIXED_PROB_MAP, seed=42)\n",
    "mixed_results = evaluate_checkpoints(X_mixed, y_test_np)\n",
    "\n",
    "# Report (clean + noise)\n",
    "def summarize_results(results, key=\"acc\"):\n",
    "    by_model = {}\n",
    "    for r in results:\n",
    "        by_model.setdefault(r[\"model_name\"], []).append(r[key])\n",
    "    summary = {m: float(np.mean(vals)) for m, vals in by_model.items()}\n",
    "    return summary\n",
    "\n",
    "print(\"\\nMean metrics per model (clean):\")\n",
    "clean_summary = summarize_results(noise_results[\"clean\"], key=\"acc\")\n",
    "for model_name in sorted(clean_summary.keys()):\n",
    "    print(f\"{model_name}: acc={clean_summary[model_name]:.4f} | f1={summarize_results(noise_results['clean'], 'f1_macro')[model_name]:.4f} | rec={summarize_results(noise_results['clean'], 'recall_macro')[model_name]:.4f}\")\n",
    "\n",
    "print(\"\\nMean metrics per model (mixed):\")\n",
    "mixed_acc = summarize_results(mixed_results, key=\"acc\")\n",
    "mixed_f1 = summarize_results(mixed_results, key=\"f1_macro\")\n",
    "mixed_rec = summarize_results(mixed_results, key=\"recall_macro\")\n",
    "for model_name in sorted(mixed_acc.keys()):\n",
    "    print(f\"{model_name}: acc={mixed_acc[model_name]:.4f} | f1={mixed_f1[model_name]:.4f} | rec={mixed_rec[model_name]:.4f}\")\n",
    "\n",
    "# Plot: confronto performance per rumore (media per modello)\n",
    "model_names = sorted({r[\"model_name\"] for rs in noise_results.values() for r in rs})\n",
    "noises = noise_keys\n",
    "acc_matrix = np.full((len(model_names), len(noises)), np.nan, dtype=np.float32)\n",
    "f1_matrix = np.full((len(model_names), len(noises)), np.nan, dtype=np.float32)\n",
    "rec_matrix = np.full((len(model_names), len(noises)), np.nan, dtype=np.float32)\n",
    "for j, noise in enumerate(noises):\n",
    "    for i, model in enumerate(model_names):\n",
    "        accs = [r[\"acc\"] for r in noise_results[noise] if r[\"model_name\"] == model]\n",
    "        f1s = [r[\"f1_macro\"] for r in noise_results[noise] if r[\"model_name\"] == model]\n",
    "        recs = [r[\"recall_macro\"] for r in noise_results[noise] if r[\"model_name\"] == model]\n",
    "        if accs:\n",
    "            acc_matrix[i, j] = float(np.mean(accs))\n",
    "        if f1s:\n",
    "            f1_matrix[i, j] = float(np.mean(f1s))\n",
    "        if recs:\n",
    "            rec_matrix[i, j] = float(np.mean(recs))\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "for i, model in enumerate(model_names):\n",
    "    plt.plot(noises, acc_matrix[i], marker=\"o\", label=model)\n",
    "plt.ylabel(\"Mean Test Accuracy\")\n",
    "plt.title(\"Performance vs rumore (media per modello)\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "for i, model in enumerate(model_names):\n",
    "    plt.plot(noises, f1_matrix[i], marker=\"o\", label=model)\n",
    "plt.ylabel(\"Macro F1\")\n",
    "plt.title(\"Macro F1 vs rumore (media per modello)\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "for i, model in enumerate(model_names):\n",
    "    plt.plot(noises, rec_matrix[i], marker=\"o\", label=model)\n",
    "plt.ylabel(\"Macro Recall\")\n",
    "plt.title(\"Macro Recall vs rumore (media per modello)\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot: confronto clean vs mixed\n",
    "clean_means = [np.nanmean(acc_matrix[i, noises.index(\"clean\")]) if \"clean\" in noises else np.nan for i in range(len(model_names))]\n",
    "mixed_means = [mixed_acc.get(m, np.nan) for m in model_names]\n",
    "x = np.arange(len(model_names))\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(x - 0.2, clean_means, width=0.4, label=\"clean\")\n",
    "plt.bar(x + 0.2, mixed_means, width=0.4, label=\"mixed\")\n",
    "plt.xticks(x, model_names, rotation=20)\n",
    "plt.ylabel(\"Mean Test Accuracy\")\n",
    "plt.title(\"Clean vs Mixed\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
