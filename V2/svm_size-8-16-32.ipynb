{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc9c88a",
   "metadata": {},
   "source": [
    "# Fruits-360 Pipeline (Color Histogram Baseline)\n",
    "Baseline notebook using color histogram features and classic ML models.\n",
    "\n",
    "**Key knobs:** `size`, `batch`, `RANDOM_STATE`, `color_bins`, `k_list`, `C_list`, `rf_depth_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b734d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils.pipeline_utils import (\n",
    "    download_dataset,\n",
    "    FruitFolderDataset,\n",
    "    dataloader_to_numpy,\n",
    "    save_checkpoint,\n",
    "    color_hist_features,\n",
    " )\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4a51c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dir: dataset/fruit360/Training\n",
      "Test dir: dataset/fruit360/Test\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = \"dataset/fruit360\"\n",
    "TRAIN_DIR = os.path.join(ROOT_DIR, \"Training\")\n",
    "TEST_DIR = os.path.join(ROOT_DIR, \"Test\")\n",
    "\n",
    "GITHUB_REPO = \"https://github.com/fruits-360/fruits-360-100x100\"\n",
    "CLONE_DIR = \"dataset/fruits-360-100x100\"\n",
    "\n",
    "if not os.path.exists(ROOT_DIR):\n",
    "    download_dataset(\n",
    "        root_dir=ROOT_DIR,\n",
    "        train_dir=TRAIN_DIR,\n",
    "        test_dir=TEST_DIR,\n",
    "        github_repo=GITHUB_REPO,\n",
    "        clone_dir=CLONE_DIR,\n",
    "    )\n",
    "\n",
    "assert os.path.exists(TRAIN_DIR)\n",
    "assert os.path.exists(TEST_DIR)\n",
    "\n",
    "print(f\"Train dir: {TRAIN_DIR}\")\n",
    "print(f\"Test dir: {TEST_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1eea627",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 32\n",
    "batch = 128\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc129bbc",
   "metadata": {},
   "source": [
    "## Experiment: HSV histogram + SVM vs image size\n",
    "Runs HSV histogram + SVM on clean test set for 8x8, 16x16, 32x32.\n",
    "Also saves checkpoints for each size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5565f4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -> 130344 images, 79 classes\n",
      "Test -> 43442 images, 79 classes\n",
      "Size 8x8 -> Val: 0.9984, Test: 0.9650, C=40\n",
      "Training -> 130344 images, 79 classes\n",
      "Test -> 43442 images, 79 classes\n",
      "Size 16x16 -> Val: 0.9999, Test: 0.9792, C=40\n",
      "Training -> 130344 images, 79 classes\n",
      "Test -> 43442 images, 79 classes\n",
      "Size 32x32 -> Val: 1.0000, Test: 0.9837, C=40\n",
      "\n",
      "Checkpoint paths:\n",
      "  8x8: artifacts/checkpoints/fruit360/color_hist/svm/20260217-184546_6751bc48\n",
      "  16x16: artifacts/checkpoints/fruit360/color_hist/svm/20260217-185416_29ca2320\n",
      "  32x32: artifacts/checkpoints/fruit360/color_hist/svm/20260217-190103_0dbeb873\n"
     ]
    }
   ],
   "source": [
    "sizes = [8, 16, 32]\n",
    "color_bins = 16\n",
    "C_list = [10, 20, 40]\n",
    "\n",
    "def run_hist_svm_for_size(img_size):\n",
    "    transform = T.Compose([\n",
    "        T.Resize((img_size, img_size)),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    full_train_dataset = FruitFolderDataset(TRAIN_DIR, transform=transform, variety=False)\n",
    "    test_dataset = FruitFolderDataset(TEST_DIR, transform=transform, variety=False)\n",
    "\n",
    "    train_size = int(0.7 * len(full_train_dataset))\n",
    "    val_size = len(full_train_dataset) - train_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        full_train_dataset,\n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(RANDOM_STATE),\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch, shuffle=False)\n",
    "\n",
    "    X_train_np, y_train_np = dataloader_to_numpy(train_loader)\n",
    "    X_val_np, y_val_np = dataloader_to_numpy(val_loader)\n",
    "    X_test_np, y_test_np = dataloader_to_numpy(test_loader)\n",
    "\n",
    "    X_train_color = color_hist_features(X_train_np, bins=color_bins, img_shape=(3, img_size, img_size))\n",
    "    X_val_color = color_hist_features(X_val_np, bins=color_bins, img_shape=(3, img_size, img_size))\n",
    "    X_test_color = color_hist_features(X_test_np, bins=color_bins, img_shape=(3, img_size, img_size))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_std = scaler.fit_transform(X_train_color)\n",
    "    X_val_std = scaler.transform(X_val_color)\n",
    "    X_test_std = scaler.transform(X_test_color)\n",
    "\n",
    "    best_svm_acc = 0.0\n",
    "    best_C = None\n",
    "    best_svm_model = None\n",
    "    for C in C_list:\n",
    "        svm = SVC(kernel=\"rbf\", C=C)\n",
    "        svm.fit(X_train_std, y_train_np)\n",
    "        y_val_pred = svm.predict(X_val_std)\n",
    "        acc = accuracy_score(y_val_np, y_val_pred)\n",
    "        if acc > best_svm_acc:\n",
    "            best_svm_acc = acc\n",
    "            best_C = C\n",
    "            best_svm_model = svm\n",
    "\n",
    "    y_test_pred = best_svm_model.predict(X_test_std)\n",
    "    test_acc = accuracy_score(y_test_np, y_test_pred)\n",
    "\n",
    "    meta_base = {\n",
    "        \"task\": \"fruit360\",\n",
    "        \"split\": \"All\",\n",
    "        \"feature\": \"color_hist\",\n",
    "        \"img_size\": img_size,\n",
    "        \"bins\": color_bins,\n",
    "        \"seed\": RANDOM_STATE,\n",
    "        \"n_classes\": len(full_train_dataset.label_to_idx),\n",
    "        \"labels\": full_train_dataset.labels,\n",
    "        \"label_to_idx\": full_train_dataset.label_to_idx,\n",
    "    }\n",
    "\n",
    "    ckpt_path = save_checkpoint(\n",
    "        best_svm_model,\n",
    "        scaler,\n",
    "        {\n",
    "            **meta_base,\n",
    "            \"model\": \"svm\",\n",
    "            \"params\": {\"kernel\": \"rbf\", \"C\": best_C},\n",
    "        },\n",
    "        save_meta=False,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"img_size\": img_size,\n",
    "        \"val_acc\": best_svm_acc,\n",
    "        \"test_acc\": test_acc,\n",
    "        \"best_C\": best_C,\n",
    "        \"ckpt_path\": ckpt_path,\n",
    "        \"model\": best_svm_model,\n",
    "        \"scaler\": scaler,\n",
    "        \"X_test_np\": X_test_np,\n",
    "        \"y_test_np\": y_test_np,\n",
    "    }\n",
    "\n",
    "results_by_size = []\n",
    "models_by_size = {}\n",
    "\n",
    "for img_size in sizes:\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    torch.manual_seed(RANDOM_STATE)\n",
    "    out = run_hist_svm_for_size(img_size)\n",
    "    results_by_size.append(out)\n",
    "    models_by_size[img_size] = out\n",
    "    print(\n",
    "        f\"Size {img_size}x{img_size} -> Val: {out['val_acc']:.4f}, \"\n",
    "        f\"Test: {out['test_acc']:.4f}, C={out['best_C']}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nCheckpoint paths:\")\n",
    "for out in results_by_size:\n",
    "    print(f\"  {out['img_size']}x{out['img_size']}: {out['ckpt_path']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb5070d",
   "metadata": {},
   "source": [
    "## 32x32 SVM: test clean vs 20% augmented test\n",
    "Applies scenarios A/B/C to 20% of the test set (A:0.4, B:0.4, C:0.2) and evaluates the 32x32 SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "321263a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32x32 test accuracy (clean): 0.9837\n",
      "32x32 test accuracy (20% augmented): 0.8852\n",
      "Augmentation distribution: {'A': 3456, 'B': 3485, 'C': 1747}\n"
     ]
    }
   ],
   "source": [
    "from utils.pipeline_utils import scenarioA, scenarioB, scenarioC\n",
    "\n",
    "AUG_RATIO_TEST = 0.20\n",
    "AUG_DIST_TEST = {\"A\": 0.4, \"B\": 0.4, \"C\": 0.2}\n",
    "\n",
    "scenario_map = {\n",
    "    \"A\": scenarioA,\n",
    "    \"B\": scenarioB,\n",
    "    \"C\": scenarioC,\n",
    "}\n",
    "\n",
    "def apply_test_augmentation(X, aug_ratio, aug_dist):\n",
    "    X_aug = X.copy()\n",
    "    n_aug = int(len(X_aug) * aug_ratio)\n",
    "    aug_indices = np.random.choice(len(X_aug), n_aug, replace=False)\n",
    "\n",
    "    counts = {\"A\": 0, \"B\": 0, \"C\": 0}\n",
    "    for idx in aug_indices:\n",
    "        r = np.random.rand()\n",
    "        if r < aug_dist[\"A\"]:\n",
    "            scenario_name = \"A\"\n",
    "        elif r < aug_dist[\"A\"] + aug_dist[\"B\"]:\n",
    "            scenario_name = \"B\"\n",
    "        else:\n",
    "            scenario_name = \"C\"\n",
    "\n",
    "        counts[scenario_name] += 1\n",
    "        img_tensor = torch.from_numpy(X_aug[idx]).float()\n",
    "        aug_img = scenario_map[scenario_name](img_tensor)\n",
    "        X_aug[idx] = aug_img.numpy()\n",
    "\n",
    "    return X_aug, counts\n",
    "\n",
    "if 32 not in models_by_size:\n",
    "    raise RuntimeError(\"Run the size sweep above before this cell.\")\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "\n",
    "model_32 = models_by_size[32][\"model\"]\n",
    "scaler_32 = models_by_size[32][\"scaler\"]\n",
    "X_test_32 = models_by_size[32][\"X_test_np\"]\n",
    "y_test_32 = models_by_size[32][\"y_test_np\"]\n",
    "\n",
    "X_test_32_aug, aug_counts = apply_test_augmentation(\n",
    "    X_test_32,\n",
    "    aug_ratio=AUG_RATIO_TEST,\n",
    "    aug_dist=AUG_DIST_TEST,\n",
    ")\n",
    "\n",
    "X_test_32_color = color_hist_features(X_test_32, bins=color_bins, img_shape=(3, 32, 32))\n",
    "X_test_32_aug_color = color_hist_features(X_test_32_aug, bins=color_bins, img_shape=(3, 32, 32))\n",
    "\n",
    "X_test_32_std = scaler_32.transform(X_test_32_color)\n",
    "X_test_32_aug_std = scaler_32.transform(X_test_32_aug_color)\n",
    "\n",
    "y_test_pred_clean = model_32.predict(X_test_32_std)\n",
    "y_test_pred_aug = model_32.predict(X_test_32_aug_std)\n",
    "\n",
    "acc_test_clean = accuracy_score(y_test_32, y_test_pred_clean)\n",
    "acc_test_aug = accuracy_score(y_test_32, y_test_pred_aug)\n",
    "\n",
    "print(f\"32x32 test accuracy (clean): {acc_test_clean:.4f}\")\n",
    "print(f\"32x32 test accuracy (20% augmented): {acc_test_aug:.4f}\")\n",
    "print(f\"Augmentation distribution: {aug_counts}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
