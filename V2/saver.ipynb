{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e8b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1761055d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241c2f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ready: dataset/fruit360\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = \"dataset/fruit360\"\n",
    "TRAIN_DIR = os.path.join(ROOT_DIR, \"Training\")\n",
    "TEST_DIR = os.path.join(ROOT_DIR, \"Test\")\n",
    "\n",
    "GITHUB_REPO = \"https://github.com/fruits-360/fruits-360-100x100\"\n",
    "CLONE_DIR = \"dataset/fruits-360-100x100\"\n",
    "\n",
    "def download_dataset():\n",
    "    os.makedirs(\"dataset\", exist_ok=True)\n",
    "    subprocess.run([\"git\", \"clone\", GITHUB_REPO, CLONE_DIR], check=True)\n",
    "    \n",
    "    os.makedirs(ROOT_DIR, exist_ok=True)\n",
    "    shutil.move(os.path.join(CLONE_DIR, \"Training\"), TRAIN_DIR)\n",
    "    shutil.move(os.path.join(CLONE_DIR, \"Test\"), TEST_DIR)\n",
    "    shutil.rmtree(CLONE_DIR, ignore_errors=True)\n",
    "\n",
    "if not os.path.exists(ROOT_DIR):\n",
    "    download_dataset()\n",
    "\n",
    "assert os.path.exists(TRAIN_DIR), f\"{TRAIN_DIR} not found\"\n",
    "assert os.path.exists(TEST_DIR), f\"{TEST_DIR} not found\"\n",
    "print(f\"Dataset ready: {ROOT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f969227",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fruit360FolderDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, variety=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.variety = variety\n",
    "        self.samples = []\n",
    "        \n",
    "        for class_name in sorted(os.listdir(root_dir)):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                continue\n",
    "            \n",
    "            label = class_name if self.variety else class_name.split()[0]\n",
    "            \n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith((\".jpg\", \".png\")):\n",
    "                    self.samples.append((os.path.join(class_dir, img_name), label))\n",
    "        \n",
    "        unique_labels = sorted({lbl for _, lbl in self.samples})\n",
    "        self.label_to_idx = {lbl: i for i, lbl in enumerate(unique_labels)}\n",
    "        self.idx_to_label = {i: lbl for lbl, i in self.label_to_idx.items()}\n",
    "        \n",
    "        print(f\"{os.path.basename(root_dir)}: {len(self.samples)} images, {len(unique_labels)} classes\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label_str = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, self.label_to_idx[label_str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b570c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numpy(loader):\n",
    "    X_list, y_list = [], []\n",
    "    for imgs, labels in loader:\n",
    "        X_list.append(imgs.numpy())\n",
    "        y_list.append(labels.numpy())\n",
    "    X = np.concatenate(X_list, axis=0)\n",
    "    y = np.concatenate(y_list, axis=0)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef491e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models will be saved in: saved_models\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = \"saved_models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "print(f\"Models will be saved in: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b77036fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configurations loaded:\n",
      "  8x8: SIZE=8, PC=55, C=100, gamma=0.01\n",
      "  16x16: SIZE=16, PC=158, C=100, gamma=0.001\n",
      "  32x32: SIZE=32, PC=66, C=10, gamma=0.001\n"
     ]
    }
   ],
   "source": [
    "MODELS_CONFIG = {\n",
    "    \"8x8\": {\n",
    "        \"size\": 8,\n",
    "        \"n_components\": 55,\n",
    "        \"C\": 100,\n",
    "        \"gamma\": 0.01,\n",
    "    },\n",
    "    \"16x16\": {\n",
    "        \"size\": 16,\n",
    "        \"n_components\": 158,\n",
    "        \"C\": 100,\n",
    "        \"gamma\": 0.001,\n",
    "    },\n",
    "    \"32x32\": {\n",
    "        \"size\": 32,\n",
    "        \"n_components\": 66,\n",
    "        \"C\": 10,\n",
    "        \"gamma\": 0.001,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Model configurations loaded:\")\n",
    "for name, cfg in MODELS_CONFIG.items():\n",
    "    print(f\"  {name}: SIZE={cfg['size']}, PC={cfg['n_components']}, C={cfg['C']}, gamma={cfg['gamma']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bafa3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING AND SAVING: 8x8\n",
      "======================================================================\n",
      "\n",
      "Loading dataset at 8x8...\n",
      "Training: 130344 images, 79 classes\n",
      "Test: 43442 images, 79 classes\n",
      "Train 91240, Val 39104, Test 43442\n",
      "Extracting numpy arrays...\n",
      "Flattened shape: (91240, 192)\n",
      "Fitting StandardScaler...\n",
      "Fitting PCA with 55 components...\n",
      "Train+Val PCA shape: (130344, 55)\n",
      "Test PCA shape: (43442, 55)\n",
      "Training SVM (C=100, gamma=0.01)...\n",
      "✓ Final test accuracy: 0.9794\n",
      "✓ Models saved:\n",
      "  - saved_models/scaler_8x8.joblib\n",
      "  - saved_models/pca_8x8.joblib\n",
      "  - saved_models/svm_8x8.joblib\n",
      "\n",
      "======================================================================\n",
      "TRAINING AND SAVING: 16x16\n",
      "======================================================================\n",
      "\n",
      "Loading dataset at 16x16...\n",
      "Training: 130344 images, 79 classes\n",
      "Test: 43442 images, 79 classes\n",
      "Train 91240, Val 39104, Test 43442\n",
      "Extracting numpy arrays...\n",
      "Flattened shape: (91240, 768)\n",
      "Fitting StandardScaler...\n",
      "Fitting PCA with 158 components...\n",
      "Train+Val PCA shape: (130344, 158)\n",
      "Test PCA shape: (43442, 158)\n",
      "Training SVM (C=100, gamma=0.001)...\n",
      "✓ Final test accuracy: 0.9813\n",
      "✓ Models saved:\n",
      "  - saved_models/scaler_16x16.joblib\n",
      "  - saved_models/pca_16x16.joblib\n",
      "  - saved_models/svm_16x16.joblib\n",
      "\n",
      "======================================================================\n",
      "TRAINING AND SAVING: 32x32\n",
      "======================================================================\n",
      "\n",
      "Loading dataset at 32x32...\n",
      "Training: 130344 images, 79 classes\n",
      "Test: 43442 images, 79 classes\n",
      "Train 91240, Val 39104, Test 43442\n",
      "Extracting numpy arrays...\n",
      "Flattened shape: (91240, 3072)\n",
      "Fitting StandardScaler...\n",
      "Fitting PCA with 66 components...\n",
      "Train+Val PCA shape: (130344, 66)\n",
      "Test PCA shape: (43442, 66)\n",
      "Training SVM (C=10, gamma=0.001)...\n",
      "✓ Final test accuracy: 0.9742\n",
      "✓ Models saved:\n",
      "  - saved_models/scaler_32x32.joblib\n",
      "  - saved_models/pca_32x32.joblib\n",
      "  - saved_models/svm_32x32.joblib\n",
      "\n",
      "======================================================================\n",
      "ALL MODELS TRAINED AND SAVED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "VARIETY = False\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "for model_name, config in MODELS_CONFIG.items():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"TRAINING AND SAVING: {model_name}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    SIZE = config[\"size\"]\n",
    "    N_COMP = config[\"n_components\"]\n",
    "    C_VAL = config[\"C\"]\n",
    "    GAMMA_VAL = config[\"gamma\"]\n",
    "    \n",
    "    transform = T.Compose([\n",
    "        T.Resize((SIZE, SIZE)),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\nLoading dataset at {SIZE}x{SIZE}...\")\n",
    "    train_full = Fruit360FolderDataset(TRAIN_DIR, transform=transform, variety=VARIETY)\n",
    "    test_dataset = Fruit360FolderDataset(TEST_DIR, transform=transform, variety=VARIETY)\n",
    "    \n",
    "    train_size = int(0.7 * len(train_full))\n",
    "    val_size = len(train_full) - train_size\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        train_full,\n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    "    )\n",
    "    \n",
    "    print(f\"Train {len(train_dataset)}, Val {len(val_dataset)}, Test {len(test_dataset)}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    print(\"Extracting numpy arrays...\")\n",
    "    X_train, y_train = extract_numpy(train_loader)\n",
    "    X_val, y_val = extract_numpy(val_loader)\n",
    "    X_test, y_test = extract_numpy(test_loader)\n",
    "    \n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_val_flat = X_val.reshape(X_val.shape[0], -1)\n",
    "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "    \n",
    "    print(f\"Flattened shape: {X_train_flat.shape}\")\n",
    "    \n",
    "    print(\"Fitting StandardScaler...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_sc = scaler.fit_transform(X_train_flat)\n",
    "    X_val_sc = scaler.transform(X_val_flat)\n",
    "    X_test_sc = scaler.transform(X_test_flat)\n",
    "    \n",
    "    print(f\"Fitting PCA with {N_COMP} components...\")\n",
    "    pca = PCA(n_components=N_COMP, random_state=RANDOM_STATE)\n",
    "    \n",
    "    X_train_val_sc = np.concatenate([X_train_sc, X_val_sc], axis=0)\n",
    "    y_train_val = np.concatenate([y_train, y_val], axis=0)\n",
    "    \n",
    "    X_train_val_pca = pca.fit_transform(X_train_val_sc)\n",
    "    X_test_pca = pca.transform(X_test_sc)\n",
    "    \n",
    "    print(f\"Train+Val PCA shape: {X_train_val_pca.shape}\")\n",
    "    print(f\"Test PCA shape: {X_test_pca.shape}\")\n",
    "    \n",
    "    print(f\"Training SVM (C={C_VAL}, gamma={GAMMA_VAL})...\")\n",
    "    svm = SVC(C=C_VAL, gamma=GAMMA_VAL, kernel='rbf', random_state=RANDOM_STATE)\n",
    "    svm.fit(X_train_val_pca, y_train_val)\n",
    "    \n",
    "    y_test_pred = svm.predict(X_test_pca)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"✓ Final test accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    scaler_path = os.path.join(MODEL_DIR, f\"scaler_{model_name}.joblib\")\n",
    "    pca_path = os.path.join(MODEL_DIR, f\"pca_{model_name}.joblib\")\n",
    "    svm_path = os.path.join(MODEL_DIR, f\"svm_{model_name}.joblib\")\n",
    "    \n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    joblib.dump(pca, pca_path)\n",
    "    joblib.dump(svm, svm_path)\n",
    "    \n",
    "    print(f\"✓ Models saved:\")\n",
    "    print(f\"  - {scaler_path}\")\n",
    "    print(f\"  - {pca_path}\")\n",
    "    print(f\"  - {svm_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL MODELS TRAINED AND SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1af206d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model loading...\n",
      "✓ 8x8: scaler, pca (55 PC), svm loaded successfully\n",
      "✓ 16x16: scaler, pca (158 PC), svm loaded successfully\n",
      "✓ 32x32: scaler, pca (66 PC), svm loaded successfully\n",
      "\n",
      "All models loaded correctly. Ready for robustness testing!\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing model loading...\")\n",
    "\n",
    "for model_name in MODELS_CONFIG.keys():\n",
    "    scaler = joblib.load(os.path.join(MODEL_DIR, f\"scaler_{model_name}.joblib\"))\n",
    "    pca = joblib.load(os.path.join(MODEL_DIR, f\"pca_{model_name}.joblib\"))\n",
    "    svm = joblib.load(os.path.join(MODEL_DIR, f\"svm_{model_name}.joblib\"))\n",
    "    \n",
    "    print(f\"✓ {model_name}: scaler, pca ({pca.n_components_} PC), svm loaded successfully\")\n",
    "\n",
    "print(\"\\nAll models loaded correctly. Ready for robustness testing!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
