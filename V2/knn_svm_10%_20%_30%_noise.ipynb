{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc9c88a",
   "metadata": {},
   "source": [
    "# Fine-grained Fruits-360 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b734d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from utils.pipeline_utils import (\n",
    "    AugmentedDatasetWrapper,\n",
    "    FruitFolderDataset,\n",
    "    color_hist_features,\n",
    "    dataloader_to_numpy,\n",
    "    download_dataset,\n",
    "    save_checkpoint,\n",
    " )\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997f105e",
   "metadata": {},
   "source": [
    "## Download and setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a4a51c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dir: dataset/fruit360/Training\n",
      "Test dir: dataset/fruit360/Test\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR = \"dataset/fruit360\"\n",
    "TRAIN_DIR = os.path.join(ROOT_DIR, \"Training\")\n",
    "TEST_DIR = os.path.join(ROOT_DIR, \"Test\")\n",
    "\n",
    "GITHUB_REPO = \"https://github.com/fruits-360/fruits-360-100x100\"\n",
    "CLONE_DIR = \"dataset/fruits-360-100x100\"\n",
    "\n",
    "if not os.path.exists(ROOT_DIR):\n",
    "    download_dataset(ROOT_DIR, TRAIN_DIR, TEST_DIR, GITHUB_REPO, CLONE_DIR)\n",
    "\n",
    "assert os.path.exists(TRAIN_DIR)\n",
    "assert os.path.exists(TEST_DIR)\n",
    "\n",
    "print(f\"Train dir: {TRAIN_DIR}\")\n",
    "print(f\"Test dir: {TEST_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88651f4c",
   "metadata": {},
   "source": [
    "## Configuration parameters\n",
    "Define image size, batch size, and noise configuration. Three noise levels: `augment_prob=0.1`, `0.2`, `0.3`. Higher probability = more frequent augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc59a46",
   "metadata": {},
   "source": [
    "## Load dataset and create base splits\n",
    "Create FruitFolderDataset for training and test. Use fine-grained variety labels (`variety=True`). Set random seed for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1610ec",
   "metadata": {},
   "source": [
    "## Create checkpoint directories\n",
    "Prepare paths for saving trained models and metadata under `artifacts/checkpoints/fruit360/level_of_noise/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1eea627",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 32\n",
    "batch = 128\n",
    "RANDOM_STATE = 42\n",
    "CKPT_ROOT = Path(\"../artifacts/checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4039cc7",
   "metadata": {},
   "source": [
    "## Create train/val splits with augmentation\n",
    "Split training data into train and validation sets. Each split uses AugmentedDatasetWrapper with the noise configuration applied during training (val/test have no augmentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78355653",
   "metadata": {},
   "source": [
    "## Create DataLoaders\n",
    "Wrap datasets in DataLoader with batching and shuffling. Training dataloader is shuffled; validation/test are ordered for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620b47f7",
   "metadata": {},
   "source": [
    "## Grid search: Noise level vs SVM hyperparameter\n",
    "Train SVM models across all combinations of: augmentation probability (0.1, 0.2, 0.3) and C values (hyperparameter). Evaluates validation accuracy for each combination. Results saved to CSV and models checkpointed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b9f9ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -> 130344 images, 79 classes\n",
      "Test -> 43442 images, 79 classes\n",
      "[{'cfg': '01_noise', 'model': 'knn', 'val_acc': 0.9897964402618658, 'test_acc': 0.9280650062151835}, {'cfg': '01_noise', 'model': 'svm', 'val_acc': 0.9949621522094927, 'test_acc': 0.9536393352055614}, {'cfg': '02_noise', 'model': 'knn', 'val_acc': 0.9860628068739771, 'test_acc': 0.9440403296349155}, {'cfg': '02_noise', 'model': 'svm', 'val_acc': 0.9932999181669394, 'test_acc': 0.9630541871921182}, {'cfg': '03_noise', 'model': 'knn', 'val_acc': 0.9845028641571195, 'test_acc': 0.9525574328990378}, {'cfg': '03_noise', 'model': 'svm', 'val_acc': 0.9927628887070377, 'test_acc': 0.9661617789236223}]\n"
     ]
    }
   ],
   "source": [
    "# Setup: Create datasets and loaders\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((size, size)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "full_train_dataset_fg = FruitFolderDataset(TRAIN_DIR, transform=val_transform, variety=False)\n",
    "test_dataset_fg = FruitFolderDataset(TEST_DIR, transform=val_transform, variety=False)\n",
    "\n",
    "train_size_fg = int(0.7 * len(full_train_dataset_fg))\n",
    "val_size_fg = len(full_train_dataset_fg) - train_size_fg\n",
    "\n",
    "train_dataset_fg, val_dataset_fg = random_split(\n",
    "    full_train_dataset_fg,\n",
    "    [train_size_fg, val_size_fg],\n",
    "    generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    ")\n",
    "\n",
    "run_names = [\n",
    "    \"01_noise\",\n",
    "    \"02_noise\",\n",
    "    \"03_noise\",\n",
    "]\n",
    "\n",
    "noise_configs = [\n",
    "    {\"name\": \"01_noise\", \"augment_prob\": 0.1, \"max_augmentations\": 1, \"use_scenarios\": True, \"scenario_weights\": [0.375, 0.375, 0.25]},\n",
    "    {\"name\": \"02_noise\", \"augment_prob\": 0.2, \"max_augmentations\": 1, \"use_scenarios\": True, \"scenario_weights\": [0.375, 0.375, 0.25]},\n",
    "    {\"name\": \"03_noise\", \"augment_prob\": 0.3, \"max_augmentations\": 1, \"use_scenarios\": True, \"scenario_weights\": [0.375, 0.375, 0.25]},\n",
    "]\n",
    "\n",
    "def make_train_loader(cfg):\n",
    "    aug_ds = AugmentedDatasetWrapper(\n",
    "        train_dataset_fg,\n",
    "        augment_prob=cfg[\"augment_prob\"],\n",
    "        max_augmentations=cfg[\"max_augmentations\"],\n",
    "        use_scenarios=cfg[\"use_scenarios\"],\n",
    "        scenario_weights=cfg.get(\"scenario_weights\"),\n",
    "    )\n",
    "    return DataLoader(aug_ds, batch_size=batch, shuffle=True)\n",
    "\n",
    "def make_val_loader(cfg):\n",
    "    aug_ds = AugmentedDatasetWrapper(\n",
    "        val_dataset_fg,\n",
    "        augment_prob=cfg[\"augment_prob\"],\n",
    "        max_augmentations=cfg[\"max_augmentations\"],\n",
    "        use_scenarios=cfg[\"use_scenarios\"],\n",
    "        scenario_weights=cfg.get(\"scenario_weights\"),\n",
    "    )\n",
    "    return DataLoader(aug_ds, batch_size=batch, shuffle=False)\n",
    "\n",
    "def compute_color_features_from_loader(loader):\n",
    "    X_np, y_np = dataloader_to_numpy(loader)\n",
    "    X_color = color_hist_features(X_np, bins=16, img_shape=(3, size, size))\n",
    "    return X_color, y_np\n",
    "\n",
    "# Test loader with 40% augmentation\n",
    "aug_test_dataset = AugmentedDatasetWrapper(\n",
    "    test_dataset_fg,\n",
    "    augment_prob=0.4,\n",
    "    max_augmentations=1,\n",
    "    use_scenarios=True,\n",
    "    scenario_weights = [0.375, 0.375, 0.25]\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(aug_test_dataset, batch_size=batch, shuffle=False)\n",
    "X_test_color, y_test = compute_color_features_from_loader(test_loader)\n",
    "\n",
    "k_list = [5, 7, 9, 11]\n",
    "C_list = [10, 20, 40]\n",
    "\n",
    "results_grid = []\n",
    "model_out_root = CKPT_ROOT / \"fruit360\"\n",
    "model_out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for cfg in noise_configs:\n",
    "    train_loader_cfg = make_train_loader(cfg)\n",
    "    val_loader_cfg = make_val_loader(cfg)\n",
    "    X_train_color, y_train = compute_color_features_from_loader(train_loader_cfg)\n",
    "    X_val_color, y_val = compute_color_features_from_loader(val_loader_cfg)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_color_std = scaler.fit_transform(X_train_color)\n",
    "    X_val_color_std = scaler.transform(X_val_color)\n",
    "    X_test_color_std = scaler.transform(X_test_color)\n",
    "\n",
    "    meta_base = {\n",
    "        \"task\": \"fruit360\",\n",
    "        \"split\": \"All\",\n",
    "        \"feature\": \"color_hist\",\n",
    "        \"img_size\": size,\n",
    "        \"bins\": 16,\n",
    "        \"seed\": RANDOM_STATE,\n",
    "        \"n_classes\": len(full_train_dataset_fg.label_to_idx),\n",
    "        \"labels\": full_train_dataset_fg.labels,\n",
    "        \"label_to_idx\": full_train_dataset_fg.label_to_idx,\n",
    "        \"noise_cfg\": cfg,\n",
    "    }\n",
    "\n",
    "    # kNN\n",
    "    best_knn_acc = 0.0\n",
    "    best_k = None\n",
    "    best_knn_model = None\n",
    "    for k in k_list:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train_color_std, y_train)\n",
    "        y_val_pred = knn.predict(X_val_color_std)\n",
    "        acc = accuracy_score(y_val, y_val_pred)\n",
    "        if acc > best_knn_acc:\n",
    "            best_knn_acc = acc\n",
    "            best_k = k\n",
    "            best_knn_model = knn\n",
    "    if best_knn_model is not None:\n",
    "        y_test_pred = best_knn_model.predict(X_test_color_std)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        run_dir = model_out_root / cfg[\"name\"] / \"knn\"\n",
    "        save_checkpoint(\n",
    "            best_knn_model,\n",
    "            scaler,\n",
    "            {**meta_base, \"model\": f\"knn-{cfg['name']}\", \"params\": {\"n_neighbors\": best_k}},\n",
    "            run_dir=run_dir,\n",
    "            save_meta=False,\n",
    "        )\n",
    "        results_grid.append({\"cfg\": cfg[\"name\"], \"model\": \"knn\", \"val_acc\": best_knn_acc, \"test_acc\": test_acc})\n",
    "\n",
    "    # SVM\n",
    "    best_svm_acc = 0.0\n",
    "    best_C = None\n",
    "    best_svm_model = None\n",
    "    for C in C_list:\n",
    "        svm = SVC(kernel=\"rbf\", gamma='scale', C=C)\n",
    "        svm.fit(X_train_color_std, y_train)\n",
    "        y_val_pred = svm.predict(X_val_color_std)\n",
    "        acc = accuracy_score(y_val, y_val_pred)\n",
    "        if acc > best_svm_acc:\n",
    "            best_svm_acc = acc\n",
    "            best_C = C\n",
    "            best_svm_model = svm\n",
    "    if best_svm_model is not None:\n",
    "        y_test_pred = best_svm_model.predict(X_test_color_std)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        run_dir = model_out_root / cfg[\"name\"] / \"svm\"\n",
    "        save_checkpoint(\n",
    "            best_svm_model,\n",
    "            scaler,\n",
    "            {**meta_base, \"model\": f\"svm-{cfg['name']}\", \"params\": {\"kernel\": \"rbf\", \"C\": best_C, \"gamma\": \"scale\"}},\n",
    "            run_dir=run_dir,\n",
    "            save_meta=False,\n",
    "        )\n",
    "        results_grid.append({\"cfg\": cfg[\"name\"], \"model\": \"svm\", \"val_acc\": best_svm_acc, \"test_acc\": test_acc})\n",
    "\n",
    "print(results_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
