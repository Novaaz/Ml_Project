{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243d3a69",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138af25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"dataset/fruit360\"\n",
    "TRAIN_DIR = os.path.join(ROOT_DIR, \"Training\")\n",
    "TEST_DIR = os.path.join(ROOT_DIR, \"Test\")\n",
    "\n",
    "GITHUB_REPO = \"https://github.com/fruits-360/fruits-360-100x100\"\n",
    "CLONE_DIR = \"dataset/fruits-360-100x100\"\n",
    "\n",
    "def download_dataset():\n",
    "    os.makedirs(\"dataset\", exist_ok=True)\n",
    "    subprocess.run([\"git\", \"clone\", GITHUB_REPO, CLONE_DIR], check=True)\n",
    "    os.makedirs(ROOT_DIR, exist_ok=True)\n",
    "    shutil.move(os.path.join(CLONE_DIR, \"Training\"), TRAIN_DIR)\n",
    "    shutil.move(os.path.join(CLONE_DIR, \"Test\"), TEST_DIR)\n",
    "    shutil.rmtree(CLONE_DIR, ignore_errors=True)\n",
    "\n",
    "if not os.path.exists(ROOT_DIR):\n",
    "    download_dataset()\n",
    "\n",
    "assert os.path.exists(TRAIN_DIR)\n",
    "assert os.path.exists(TEST_DIR)\n",
    "\n",
    "print(f\"Train dir: {TRAIN_DIR}\")\n",
    "print(f\"Test dir: {TEST_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae0f355",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d9b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FruitFolderDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset to load and preprocess the fruit images from folder structure.\n",
    "\n",
    "    root_dir: path to Training/ or Test/\n",
    "    variety:  False -> macro label (Apple, Banana, ...)\n",
    "              True  -> fine-grained label (Apple Braeburn, ...)\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None, variety=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.variety = variety\n",
    "        self.samples = []\n",
    "\n",
    "        for class_name in sorted(os.listdir(root_dir)):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                continue\n",
    "\n",
    "            label_str = class_name if variety else class_name.split()[0]\n",
    "\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith((\".jpg\", \".png\")):\n",
    "                    self.samples.append((os.path.join(class_dir, img_name), label_str))\n",
    "\n",
    "        self.labels = sorted({lbl for _, lbl in self.samples})\n",
    "        self.label_to_idx = {lbl: i for i, lbl in enumerate(self.labels)}\n",
    "        self.idx_to_label = {i: lbl for lbl, i in self.label_to_idx.items()}\n",
    "\n",
    "        print(f\"{os.path.basename(root_dir)} -> {len(self.samples)} images, {len(self.labels)} classes\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label_str = self.samples[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image)\n",
    "        else:\n",
    "            img = image\n",
    "\n",
    "        label_idx = self.label_to_idx[label_str]\n",
    "        return img, label_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781eb13",
   "metadata": {},
   "source": [
    "# VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARS\n",
    "size = 8\n",
    "random_state = 42\n",
    "batch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de7af7",
   "metadata": {},
   "source": [
    "## 1. BIG AHH DATASET Aka Totale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09373320",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = T.Compose([\n",
    "    T.Resize((size, size)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "full_train_dataset = FruitFolderDataset(TRAIN_DIR, transform=val_transform, variety=False)\n",
    "test_dataset = FruitFolderDataset(TEST_DIR, transform=val_transform, variety=False)\n",
    "\n",
    "train_size = int(0.7 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_train_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Validation size:\", len(val_dataset))\n",
    "print(\"Test size:\", len(test_dataset))\n",
    "print(\"Classes:\", len(full_train_dataset.label_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc02ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a5033d",
   "metadata": {},
   "source": [
    "### 1.1 BIG AHH DATASET BUT RACISTS Aka Fine-Grained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6891dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dataset_fg = FruitFolderDataset(TRAIN_DIR, transform=val_transform, variety=True)\n",
    "test_dataset_fg = FruitFolderDataset(TEST_DIR, transform=val_transform, variety=True)\n",
    "\n",
    "train_size_fg = int(0.7 * len(full_train_dataset_fg))\n",
    "val_size_fg = len(full_train_dataset_fg) - train_size_fg\n",
    "\n",
    "train_dataset_fg, val_dataset_fg = random_split(\n",
    "    full_train_dataset_fg,\n",
    "    [train_size_fg, val_size_fg],\n",
    "    generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    ")\n",
    "\n",
    "train_loader_fg = DataLoader(train_dataset_fg, batch_size=batch, shuffle=True)\n",
    "val_loader_fg = DataLoader(val_dataset_fg, batch_size=batch, shuffle=False)\n",
    "test_loader_fg = DataLoader(test_dataset_fg, batch_size=batch, shuffle=False)\n",
    "\n",
    "print(\"Fine-grained -> Train:\", len(train_dataset_fg),\n",
    "      \"Val:\", len(val_dataset_fg),\n",
    "      \"Test:\", len(test_dataset_fg),\n",
    "      \"Classes:\", len(full_train_dataset_fg.label_to_idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c532d9a4",
   "metadata": {},
   "source": [
    "## 2. DOMAIN FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DOMAIN FILTERING (solo frutta, escludendo verdure)\n",
    "\n",
    "vegetables = ['Beans', 'Beetroot', 'Cabbage', 'Carrot', 'Cauliflower', 'Corn',\n",
    "              'Cucumber', 'Eggplant', 'Ginger', 'Kohlrabi', 'Onion', 'Pepper',\n",
    "              'Potato', 'Tomato', 'Zucchini']\n",
    "\n",
    "def filter_labels(dataset, drop_labels):\n",
    "    keep_indices = []\n",
    "    for idx in range(len(dataset.samples)):\n",
    "        _, label_str = dataset.samples[idx]\n",
    "        if label_str not in drop_labels:\n",
    "            keep_indices.append(idx)\n",
    "    print(f\"Kept {len(keep_indices)} / {len(dataset.samples)} samples\")\n",
    "    # creiamo un \"view\" semplice usando un sottoinsieme di samples\n",
    "    filtered = FruitFolderDataset(dataset.root_dir, transform=dataset.transform, variety=False)\n",
    "    filtered.samples = [dataset.samples[i] for i in keep_indices]\n",
    "    filtered.labels = sorted({lbl for _, lbl in filtered.samples})\n",
    "    filtered.label_to_idx = {lbl: i for i, lbl in enumerate(filtered.labels)}\n",
    "    filtered.idx_to_label = {i: lbl for lbl, i in filtered.label_to_idx.items()}\n",
    "    return filtered\n",
    "\n",
    "full_train_dataset_fruit = FruitFolderDataset(TRAIN_DIR, transform=val_transform, variety=False)\n",
    "full_train_dataset_fruit = filter_labels(full_train_dataset_fruit, vegetables)\n",
    "\n",
    "test_dataset_fruit = FruitFolderDataset(TEST_DIR, transform=val_transform, variety=False)\n",
    "test_dataset_fruit = filter_labels(test_dataset_fruit, vegetables)\n",
    "\n",
    "train_size_fruit = int(0.7 * len(full_train_dataset_fruit))\n",
    "val_size_fruit = len(full_train_dataset_fruit) - train_size_fruit\n",
    "\n",
    "train_dataset_fruit, val_dataset_fruit = random_split(\n",
    "    full_train_dataset_fruit,\n",
    "    [train_size_fruit, val_size_fruit],\n",
    "    generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_dataset_fruit))\n",
    "print(\"Validation size:\", len(val_dataset_fruit))\n",
    "print(\"Test size:\", len(test_dataset_fruit))\n",
    "print(\"Fruit-only classes:\", len(full_train_dataset_fruit.label_to_idx))\n",
    "\n",
    "train_loader_fruit = DataLoader(train_dataset_fruit, batch_size=batch, shuffle=True)\n",
    "val_loader_fruit = DataLoader(val_dataset_fruit, batch_size=batch, shuffle=False)\n",
    "test_loader_fruit = DataLoader(test_dataset_fruit, batch_size=batch, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a991a4a",
   "metadata": {},
   "source": [
    "# 3. LOW SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ab1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subset_folder(dataset, subset_type='none',\n",
    "                         samples_per_label=None,\n",
    "                         subset_fraction=None,\n",
    "                         total_samples=None,\n",
    "                         random_state=RANDOM_STATE):\n",
    "    \n",
    "    rng = torch.Generator().manual_seed(random_state)\n",
    "\n",
    "    label_to_indices = {}\n",
    "    for idx, (_, label_str) in enumerate(dataset.samples):\n",
    "        label_to_indices.setdefault(label_str, []).append(idx)\n",
    "\n",
    "    selected_indices = []\n",
    "\n",
    "    if subset_type == 'per_label' and samples_per_label is not None:\n",
    "        for label, idxs in label_to_indices.items():\n",
    "            idxs_tensor = torch.tensor(idxs)\n",
    "            perm = torch.randperm(len(idxs_tensor), generator=rng)\n",
    "            take = min(len(idxs_tensor), samples_per_label)\n",
    "            chosen = idxs_tensor[perm[:take]].tolist()\n",
    "            selected_indices.extend(chosen)\n",
    "        print(f\"Subset with {samples_per_label} samples per label\")\n",
    "\n",
    "    elif subset_type == 'fraction' and subset_fraction is not None:\n",
    "        all_indices = torch.arange(len(dataset.samples))\n",
    "        perm = torch.randperm(len(all_indices), generator=rng)\n",
    "        take = int(len(all_indices) * subset_fraction)\n",
    "        selected_indices = all_indices[perm[:take]].tolist()\n",
    "        print(f\"Subset with {subset_fraction*100}% of the dataset\")\n",
    "\n",
    "    elif subset_type == 'total' and total_samples is not None:\n",
    "        all_indices = torch.arange(len(dataset.samples))\n",
    "        perm = torch.randperm(len(all_indices), generator=rng)\n",
    "        take = min(len(all_indices), total_samples)\n",
    "        selected_indices = all_indices[perm[:take]].tolist()\n",
    "        print(f\"Subset with {total_samples} total samples\")\n",
    "\n",
    "    else:\n",
    "        print(\"No subset applied\")\n",
    "        selected_indices = list(range(len(dataset.samples)))\n",
    "\n",
    "    subset = FruitFolderDataset(dataset.root_dir, transform=dataset.transform, variety=False)\n",
    "    subset.samples = [dataset.samples[i] for i in selected_indices]\n",
    "    subset.labels = sorted({lbl for _, lbl in subset.samples})\n",
    "    subset.label_to_idx = {lbl: i for i, lbl in enumerate(subset.labels)}\n",
    "    subset.idx_to_label = {i: lbl for lbl, i in subset.label_to_idx.items()}\n",
    "\n",
    "    print(f\"\\nFinal subset: {len(subset.samples)} samples\")\n",
    "    print(f\"Total labels: {len(subset.labels)}\")\n",
    "    return subset\n",
    "\n",
    "# esempio: 500 immagini per label sul dataset macro (tutte le categorie)\n",
    "base_dataset = FruitFolderDataset(TRAIN_DIR, transform=val_transform, variety=False)\n",
    "subset_dataset = create_subset_folder(\n",
    "    base_dataset,\n",
    "    subset_type='per_label',\n",
    "    samples_per_label=500,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "train_size_sub = int(0.7 * len(subset_dataset))\n",
    "val_size_sub = len(subset_dataset) - train_size_sub\n",
    "\n",
    "train_dataset_sub, val_dataset_sub = random_split(\n",
    "    subset_dataset,\n",
    "    [train_size_sub, val_size_sub],\n",
    "    generator=torch.Generator().manual_seed(RANDOM_STATE)\n",
    ")\n",
    "\n",
    "test_dataset_sub = FruitFolderDataset(TEST_DIR, transform=val_transform, variety=False)\n",
    "\n",
    "print(\"\\nTrain size:\", len(train_dataset_sub))\n",
    "print(\"Validation size:\", len(val_dataset_sub))\n",
    "print(\"Test size:\", len(test_dataset_sub))\n",
    "\n",
    "train_loader_sub = DataLoader(train_dataset_sub, batch_size=batch, shuffle=True)\n",
    "val_loader_sub = DataLoader(val_dataset_sub, batch_size=batch, shuffle=False)\n",
    "test_loader_sub = DataLoader(test_dataset_sub, batch_size=batch, shuffle=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
